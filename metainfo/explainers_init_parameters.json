{
 "Zorro": {
  "greedy": ["Greedy", "bool", true, null, "?"],
  "add_noise": ["Noise", "bool", false, null, "?"],
  "samples": ["Samples", "int", 100, {"min": 1}, "Number of random noise samples to control fidelity"]
},

 "SubgraphX": {
  "rollout": ["Rollout","int",8,{"min": 1},"Number of iteration to get the prediction"],
  "min_atoms": ["Min atoms","int",10,{"min": 1},"Number of atoms of the leaf node in search tree"],
  "c_puct": ["C-puct","float",8.0,{"min": 0},"The hyperparameter which encourages the exploration"],
  "expand_atoms": ["Expand atoms","int",4,{"min": 1},"The number of atoms to expand when extend the child nodes in the search tree"],
  "local_radius": ["Local radius","int",4,{"min": 1},"Number of local radius to calculate"],
  "sample_num": ["Samples","int",25,{"min": 1},"Sampling time of monte carlo sampling approximation for mc_shapley"],
  "reward_method": ["Reward","string","mc_l_shapley",["gnn_score","l_shapley","mc_shapley","mc_l_shapley","nc_mc_l_shapley"],"The command string to select the ???"],
  "high2low": ["high2low","bool",false,{},"Whether to expand children nodes from high degree to low degree when extend the child nodes in the search tree"],
  "subgraph_building_method": ["subgraph_building_method","string","zero_filling",["zero_filling","split"],null]
 },

 "GNNExplainer(torch-geom)": {
  "epochs":  ["Epochs","int",200,{"min": 1},"The number of epochs to train"],
  "lr": ["Learn rate","float",0.01,{"min": 0, "step": 0.0001},"The learning rate to apply"],
  "node_mask_type": ["Node mask","string","object",["None","object","common_attributes","attributes"],"The type of mask to apply on nodes"],
  "edge_mask_type": ["Edge mask","string","object",["None","object","common_attributes","attributes"],"The type of mask to apply on edges"],
  "mode": ["Mode","string","multiclass_classification",["binary_classification","multiclass_classification","regression"],"The mode of the model"],
  "return_type": ["Model return","string","log_probs",["raw","prob","log_probs"],"Denotes the type of output from model. Valid inputs are 'log_probs' (the model returns the logarithm of probabilities), 'prob' (the model returns probabilities), 'raw' (the model returns raw scores)"],
  "edge_size": ["edge_size","float",0.005,{"min": 0, "step": 0.001},""],
  "edge_reduction": ["edge_reduction","string","sum",["sum","mean","max","min"],""],
  "node_feat_size": ["node_feat_size","float",1.0,{},""],
  "node_feat_reduction": ["node_feat_reduction","string","mean",["mean","max","min"],""],
  "edge_ent": ["edge_ent","float",1.0,{"min": 0, "step": 0.01},""],
  "node_feat_ent": ["node_feat_ent","float",0.1,{"min": 0, "step": 0.1},""],
  "EPS": ["Epsilon","float",1e-15,{},""]
 },

 "GNNExplainer(dig)": {
  "epochs":  ["Epochs","int",100,{"min": 1},"The number of epochs to train"],
  "lr": ["Learn rate","float",0.01,{"min": 0, "step": 0.0001},"The learning rate to apply"],
  "coff_size": ["alpha","float",0.001,{"min": 0, "step": 0.0001},"Contribution of element edge_mask weights compared to cross_entropy to the loss function"],
  "coff_ent": ["beta","float",0.001,{"min": 0, "step": 0.0001},"Contribution of the average value of the entropy calculated on the edge_mask compared to the loss in the loss function"]
 },

 "GraphMask": {
  "epochs": ["Epochs","int",100,{"min": 1},"The number of epochs to train"],
  "lr": ["Learn rate","float",0.01,{"min": 0, "step": 0.0001},"The learning rate to apply"],
  "coff_size": ["alpha","float",0.001,{"min": 0, "step": 0.0001},"Entropy parameter"],
  "coff_ent": ["beta","float",0.001,{"min": 0, "step": 0.0001},"Contribution of the average value of the entropy calculated on the edge_mask compared to the loss in the loss function"],
  "allowance": ["Allowance","float",0.03,{"min": 0, "step": 0.0001}, "Preparing parameter for lagrangian_optimization"]
 },

 "PGMExplainer": {
  "perturbation_mode": ["Perturbation mode","string","randint",["randint","mean","zero","max","uniform"],"The method to generate the variations in features"],
  "perturbations_is_positive_only": ["Perturbation is positive only","bool",false,{},"If set True, restrict perturbed values to be positive"],
  "is_perturbation_scaled": ["Is perturbation scaled","bool",false,{},"If set True, will normalize the range of the perturbed features"],
  "num_samples": ["Num samples","int",100,{"min": 1},"The number of samples of perturbations used to test the significance of nodes to the prediction"],
  "max_subgraph_size": ["Max subgraph size","int",5,{"min": 1},"The maximum number of neighbors to consider for the explanation"],
  "significance_threshold": ["Significance threshold","float",0.05,{},"The statistical threshold (p-value) for which a node is considered to have an effect on the prediction"],
  "pred_threshold": ["Pred threshold","float",0.1,{},"The buffer value (in range [0, 1] to consider the output from a perturbed data to be different from the original"],
  "mode": ["Mode","string","multiclass_classification",["binary_classification","multiclass_classification"],"The mode of the model"],
  "return_type": ["Model return","string","log_probs",["raw","prob","log_probs"],"Denotes the type of output from model. Valid inputs are 'log_probs' (the model returns the logarithm of probabilities), 'prob' (the model returns probabilities), 'raw' (the model returns raw scores)"]
 },

 "PGExplainer": {
  "epochs":  ["Epochs","int",30,{"min": 1},"The number of epochs to train"],
  "lr": ["Learn rate","float",0.003,{"min": 0, "step": 0.0001},"The learning rate to apply"],
  "node_mask_type": ["Node mask","string","object",["None","object","common_attributes","attributes"],"The type of mask to apply on nodes"],
  "edge_mask_type": ["Edge mask","string","object",["None","object","common_attributes","attributes"],"The type of mask to apply on edges"],
  "mode": ["Mode","string","multiclass_classification",["binary_classification","multiclass_classification","regression"],"The mode of the model"],
  "return_type": ["Model return","string","log_probs",["raw","prob","log_probs"],"Denotes the type of output from model. Valid inputs are 'log_probs' (the model returns the logarithm of probabilities), 'prob' (the model returns probabilities), 'raw' (the model returns raw scores)"]
 },

 "PGExplainer(dig)": {
  "epochs":  ["Epochs","int",20,{"min": 1},"The number of epochs to train"],
  "lr": ["Learn rate","float",0.003,{"min": 0, "step": 0.0001},"The learning rate to apply"]
 },

 "ProtGNN": {
 },

 "_Dummy": {
  "init_arg": ["init arg","int",1,{"min": 0},"Just an argument"]
 },

 "NeuralAnalysis": {
  "task": ["task", "string", "MUTAG", ["MUTAG", "MUTAGENICITY", "PROTEINS", "NCI", "BA", "IMDB", "REDDIT", "SST", "BA2Motif"], "Domain field of Dataset"]
 }

}

